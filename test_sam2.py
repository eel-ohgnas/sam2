"""
SAM2 íŒŒì¸íŠœë‹ ê²°ê³¼ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
í•™ìŠµëœ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ì„¸ë¶„í™”ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from pathlib import Path

try:
    import torch
    from sam2.build_sam import build_sam2
    from sam2.sam2_image_predictor import SAM2ImagePredictor
    SAM2_AVAILABLE = True
except ImportError:
    SAM2_AVAILABLE = False
    print("âš ï¸ SAM2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def show_mask(mask, ax, color=None):
    """ë§ˆìŠ¤í¬ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
    if color is None:
        color = np.array([30/255, 144/255, 255/255, 0.6])
    h, w = mask.shape[-2:]
    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
    ax.imshow(mask_image)


def show_points(coords, labels, ax, marker_size=375):
    """í¬ì¸íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
    pos_points = coords[labels == 1]
    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='lime',
               marker='*', s=marker_size, edgecolor='white', linewidth=1.5)


def test_on_image(image_path, predictor, output_path=None):
    """ë‹¨ì¼ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸"""
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = Image.open(image_path).convert("RGB")
    image = np.array(image)

    h, w = image.shape[:2]
    center_point = np.array([[w // 2, h // 2]])
    point_labels = np.array([1])

    # ì˜ˆì¸¡
    predictor.set_image(image)
    masks, scores, _ = predictor.predict(
        point_coords=center_point,
        point_labels=point_labels,
        multimask_output=True
    )

    # ì‹œê°í™”
    fig, axes = plt.subplots(1, 4, figsize=(16, 4))

    # ì›ë³¸
    axes[0].imshow(image)
    show_points(center_point, point_labels, axes[0])
    axes[0].set_title("Input (center click)")
    axes[0].axis("off")

    # ë§ˆìŠ¤í¬ë“¤
    for i, (mask, score) in enumerate(zip(masks[:3], scores[:3])):
        axes[i+1].imshow(image)
        show_mask(mask, axes[i+1])
        axes[i+1].set_title(f"Mask {i+1} (score: {score:.3f})")
        axes[i+1].axis("off")

    plt.tight_layout()

    if output_path:
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"ğŸ’¾ ì €ì¥: {output_path}")

    plt.close()
    return masks, scores


def main():
    if not SAM2_AVAILABLE:
        print("âŒ SAM2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # ì„¤ì •
    config = {
        'model_cfg': 'configs/sam2.1/sam2.1_hiera_s.yaml',
        'original_checkpoint': 'checkpoints/sam2.1_hiera_small.pt',
        'finetuned_checkpoint': 'output/sam2_finetuned_best.pt',
        'test_image_dir': 'data/images/val',
        'output_dir': 'output/test_results',
    }

    # ì¶œë ¥ í´ë”
    os.makedirs(config['output_dir'], exist_ok=True)

    # ë””ë°”ì´ìŠ¤
    if torch.backends.mps.is_available():
        device = "mps"
    elif torch.cuda.is_available():
        device = "cuda"
    else:
        device = "cpu"
    print(f"ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {device}")

    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì°¾ê¸°
    test_dir = Path(config['test_image_dir'])
    test_images = list(test_dir.glob("*.jpg")) + list(test_dir.glob("*.png"))

    if len(test_images) == 0:
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {config['test_image_dir']}")
        return

    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(test_images)}ê°œ")

    # ì›ë³¸ ëª¨ë¸ ë¡œë“œ
    print("\nğŸ“¦ ì›ë³¸ SAM2 ëª¨ë¸ ë¡œë“œ ì¤‘...")
    model_original = build_sam2(
        config['model_cfg'],
        config['original_checkpoint'],
        device=device
    )
    predictor_original = SAM2ImagePredictor(model_original)

    # í…ŒìŠ¤íŠ¸ (ì²˜ìŒ 5ê°œ)
    print("\nğŸ§ª ì›ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸:")
    for img_path in test_images[:5]:
        output_path = os.path.join(config['output_dir'], f"original_{img_path.stem}.png")
        test_on_image(img_path, predictor_original, output_path)

    print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"ğŸ“‚ ê²°ê³¼ ìœ„ì¹˜: {config['output_dir']}/")


if __name__ == "__main__":
    main()
