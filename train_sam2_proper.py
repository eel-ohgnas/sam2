"""
SAM2 íŒŒì¸íŠœë‹ - ê²€ì¦ëœ ë°©ì‹ (sagieppel ê¸°ë°˜)
Kvasir-SEG ë°ì´í„°ì…‹ + Apple Silicon MPS ì§€ì›

ì°¸ê³ : https://github.com/sagieppel/fine-tune-train_segment_anything_2_in_60_lines_of_code
"""

import os
import numpy as np
import torch
import cv2
from pathlib import Path
from tqdm import tqdm

from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor

# ============ ì„¤ì • ============
CONFIG = {
    'checkpoint': 'checkpoints/sam2.1_hiera_small.pt',
    'model_cfg': 'configs/sam2.1/sam2.1_hiera_s.yaml',
    'image_dir': 'data/images/train',
    'mask_dir': 'data/masks/train',
    'output_dir': 'output',
    'iterations': 3000,  # í•™ìŠµ ë°˜ë³µ íšŸìˆ˜
    'save_every': 500,   # ì €ì¥ ì£¼ê¸°
    'lr': 1e-5,
    'weight_decay': 4e-5,
}


def load_data(image_dir, mask_dir):
    """ë°ì´í„°ì…‹ ë¡œë“œ"""
    data = []
    image_dir = Path(image_dir)
    mask_dir = Path(mask_dir)

    for img_path in sorted(image_dir.glob("*")):
        if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:
            # ë§ˆìŠ¤í¬ ì°¾ê¸°
            mask_path = mask_dir / (img_path.stem + ".png")
            if not mask_path.exists():
                mask_path = mask_dir / (img_path.stem + ".jpg")
            if mask_path.exists():
                data.append({
                    'image': str(img_path),
                    'mask': str(mask_path)
                })

    print(f"ğŸ“ ë¡œë“œëœ ë°ì´í„°: {len(data)}ê°œ")
    return data


def read_batch(data, device):
    """ëœë¤ ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ ìŒ ì½ê¸°"""
    while True:
        # ëœë¤ ì„ íƒ
        entry = data[np.random.randint(len(data))]

        # ì´ë¯¸ì§€ ì½ê¸° (BGR -> RGB)
        img = cv2.imread(entry['image'])
        if img is None:
            continue
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # ë§ˆìŠ¤í¬ ì½ê¸°
        mask = cv2.imread(entry['mask'], cv2.IMREAD_GRAYSCALE)
        if mask is None:
            continue

        # ë¦¬ì‚¬ì´ì¦ˆ (ìµœëŒ€ 1024)
        r = min(1024 / img.shape[1], 1024 / img.shape[0])
        if r < 1:
            img = cv2.resize(img, (int(img.shape[1] * r), int(img.shape[0] * r)))
            mask = cv2.resize(mask, (int(mask.shape[1] * r), int(mask.shape[0] * r)),
                            interpolation=cv2.INTER_NEAREST)

        # ì´ì§„í™”
        mask = (mask > 127).astype(np.uint8)

        # ë§ˆìŠ¤í¬ê°€ ë¹„ì–´ìˆìœ¼ë©´ ìŠ¤í‚µ
        if mask.sum() < 100:
            continue

        # ë§ˆìŠ¤í¬ì—ì„œ ëœë¤ í¬ì¸íŠ¸ ì„ íƒ
        coords = np.argwhere(mask > 0)
        if len(coords) == 0:
            continue

        yx = coords[np.random.randint(len(coords))]
        point = np.array([[[yx[1], yx[0]]]])  # (1, 1, 2) - x, y
        label = np.array([[1]])  # foreground

        # ë§ˆìŠ¤í¬ë¥¼ (1, H, W) í˜•íƒœë¡œ
        mask = mask[np.newaxis, :, :]

        return img, mask, point, label


def main():
    print("\n" + "="*60)
    print("ğŸš€ SAM2 íŒŒì¸íŠœë‹ (ê²€ì¦ëœ ë°©ì‹)")
    print("="*60)

    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("âœ… Apple Silicon GPU (MPS) ì‚¬ìš©")
        use_amp = False  # MPSëŠ” AMP ë¯¸ì§€ì›
    elif torch.cuda.is_available():
        device = torch.device("cuda")
        print("âœ… NVIDIA GPU (CUDA) ì‚¬ìš©")
        use_amp = True
    else:
        device = torch.device("cpu")
        print("âš ï¸ CPU ì‚¬ìš©")
        use_amp = False

    # ë°ì´í„° ë¡œë“œ
    data = load_data(CONFIG['image_dir'], CONFIG['mask_dir'])
    if len(data) == 0:
        print("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return

    # ëª¨ë¸ ë¡œë“œ
    print("\nğŸ“¦ SAM2 ëª¨ë¸ ë¡œë“œ ì¤‘...")
    device_str = str(device).split(':')[0]  # "mps" or "cuda" or "cpu"

    sam2_model = build_sam2(
        CONFIG['model_cfg'],
        CONFIG['checkpoint'],
        device=device_str
    )
    predictor = SAM2ImagePredictor(sam2_model)

    # í•™ìŠµ ëª¨ë“œ ì„¤ì •
    predictor.model.sam_mask_decoder.train(True)
    predictor.model.sam_prompt_encoder.train(True)
    # Image encoderëŠ” í•™ìŠµí•˜ì§€ ì•ŠìŒ (ë©”ëª¨ë¦¬ ì ˆì•½)

    # í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° í™•ì¸
    trainable = sum(p.numel() for p in predictor.model.parameters() if p.requires_grad)
    total = sum(p.numel() for p in predictor.model.parameters())
    print(f"ğŸ“Š í•™ìŠµ íŒŒë¼ë¯¸í„°: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)")

    # Optimizer
    optimizer = torch.optim.AdamW(
        params=predictor.model.parameters(),
        lr=CONFIG['lr'],
        weight_decay=CONFIG['weight_decay']
    )

    # Mixed Precision (CUDA only)
    if use_amp:
        scaler = torch.cuda.amp.GradScaler()

    # ì¶œë ¥ í´ë”
    os.makedirs(CONFIG['output_dir'], exist_ok=True)

    # í•™ìŠµ ë£¨í”„
    print(f"\nğŸ¯ í•™ìŠµ ì‹œì‘: {CONFIG['iterations']} iterations")
    print("-" * 60)

    mean_iou = 0
    best_iou = 0

    pbar = tqdm(range(CONFIG['iterations']), desc="Training")
    for itr in pbar:
        try:
            # ë°ì´í„° ë¡œë“œ
            image, mask, input_point, input_label = read_batch(data, device)

            # Forward pass
            if use_amp:
                with torch.cuda.amp.autocast():
                    loss, iou = forward_pass(predictor, image, mask, input_point, input_label, device)
            else:
                loss, iou = forward_pass(predictor, image, mask, input_point, input_label, device)

            if loss is None:
                continue

            # Backward pass
            predictor.model.zero_grad()

            if use_amp:
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
            else:
                loss.backward()
                optimizer.step()

            # í†µê³„ ì—…ë°ì´íŠ¸
            current_iou = iou.mean().item()
            mean_iou = mean_iou * 0.99 + 0.01 * current_iou

            pbar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'IoU': f'{mean_iou:.4f}'
            })

            # ëª¨ë¸ ì €ì¥
            if (itr + 1) % CONFIG['save_every'] == 0:
                save_path = os.path.join(CONFIG['output_dir'], f'sam2_iter_{itr+1}.pt')
                torch.save(predictor.model.state_dict(), save_path)
                print(f"\nğŸ’¾ ì €ì¥: {save_path} (IoU: {mean_iou:.4f})")

                if mean_iou > best_iou:
                    best_iou = mean_iou
                    best_path = os.path.join(CONFIG['output_dir'], 'sam2_best.pt')
                    torch.save(predictor.model.state_dict(), best_path)
                    print(f"ğŸ† ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥: {best_path}")

        except Exception as e:
            print(f"\nâš ï¸ ì˜¤ë¥˜: {e}")
            continue

    # ìµœì¢… ì €ì¥
    final_path = os.path.join(CONFIG['output_dir'], 'sam2_final.pt')
    torch.save(predictor.model.state_dict(), final_path)

    print("\n" + "="*60)
    print("âœ… í•™ìŠµ ì™„ë£Œ!")
    print("="*60)
    print(f"""
ğŸ“Š ê²°ê³¼:
   - ìµœì¢… IoU: {mean_iou:.4f}
   - ë² ìŠ¤íŠ¸ IoU: {best_iou:.4f}
   - ì €ì¥ ìœ„ì¹˜: {CONFIG['output_dir']}/

ğŸ“ ìƒì„±ëœ íŒŒì¼:
   - sam2_best.pt (ë² ìŠ¤íŠ¸ ëª¨ë¸)
   - sam2_final.pt (ìµœì¢… ëª¨ë¸)
""")


def forward_pass(predictor, image, mask, input_point, input_label, device):
    """Forward pass with gradient"""

    # ì´ë¯¸ì§€ ì¸ì½”ë”©
    predictor.set_image(image)

    # Prompt ì¤€ë¹„
    mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(
        input_point, input_label, box=None, mask_logits=None, normalize_coords=True
    )

    # Prompt ì¸ì½”ë”©
    sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(
        points=(unnorm_coords, labels),
        boxes=None,
        masks=None,
    )

    # Mask Decoder
    batched_mode = unnorm_coords.shape[0] > 1
    high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features["high_res_feats"]]

    low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(
        image_embeddings=predictor._features["image_embed"][-1].unsqueeze(0),
        image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),
        sparse_prompt_embeddings=sparse_embeddings,
        dense_prompt_embeddings=dense_embeddings,
        multimask_output=True,
        repeat_image=batched_mode,
        high_res_features=high_res_features,
    )

    # ë§ˆìŠ¤í¬ ì—…ìŠ¤ì¼€ì¼
    prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])

    # Ground truth
    gt_mask = torch.tensor(mask.astype(np.float32), device=device)

    # ì˜ˆì¸¡ ë§ˆìŠ¤í¬ (sigmoid ì ìš©)
    prd_mask = torch.sigmoid(prd_masks[:, 0])

    # Segmentation Loss (Binary Cross Entropy)
    seg_loss = (
        -gt_mask * torch.log(prd_mask + 1e-5)
        - (1 - gt_mask) * torch.log(1 - prd_mask + 1e-5)
    ).mean()

    # IoU Score Loss
    inter = (gt_mask * (prd_mask > 0.5)).sum(dim=(1, 2))
    union = gt_mask.sum(dim=(1, 2)) + (prd_mask > 0.5).sum(dim=(1, 2)) - inter
    iou = inter / (union + 1e-5)

    score_loss = torch.abs(prd_scores[:, 0] - iou).mean()

    # Total Loss
    loss = seg_loss + score_loss * 0.05

    return loss, iou


if __name__ == "__main__":
    main()
