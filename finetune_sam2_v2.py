"""
SAM2 íŒŒì¸íŠœë‹ ìŠ¤í¬ë¦½íŠ¸ v2 (ìˆ˜ì •ëœ ë²„ì „)
ì°¸ê³ : https://github.com/sagieppel/fine-tune-train_segment_anything_2_in_60_lines_of_code

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” SAM2ImagePredictorë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¸íŠœë‹í•©ë‹ˆë‹¤.
í•µì‹¬: predictor._featuresë¥¼ í™œìš©í•˜ì—¬ gradient ì „íŒŒ ê°€ëŠ¥í•˜ê²Œ í•¨
"""

import os
import random
from pathlib import Path

import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
from tqdm import tqdm

# SAM2 imports
try:
    from sam2.build_sam import build_sam2
    from sam2.sam2_image_predictor import SAM2ImagePredictor
    SAM2_AVAILABLE = True
except ImportError:
    SAM2_AVAILABLE = False
    print("âš ï¸ SAM2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def read_image_and_mask(image_path, mask_path, target_size=1024):
    """ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = Image.open(image_path).convert("RGB")
    orig_size = image.size
    image = image.resize((target_size, target_size), Image.BILINEAR)
    image = np.array(image)

    # ë§ˆìŠ¤í¬ ë¡œë“œ
    mask = Image.open(mask_path).convert("L")
    mask = mask.resize((target_size, target_size), Image.NEAREST)
    mask = np.array(mask)
    mask = (mask > 127).astype(np.float32)

    return image, mask


def get_points_from_mask(mask, num_points=1):
    """ë§ˆìŠ¤í¬ì—ì„œ í¬ì¸íŠ¸ë¥¼ ìƒ˜í”Œë§í•©ë‹ˆë‹¤."""
    ys, xs = np.where(mask > 0.5)
    if len(ys) == 0:
        # ë¹ˆ ë§ˆìŠ¤í¬ë©´ ì¤‘ì•™ì  ë°˜í™˜
        h, w = mask.shape
        return np.array([[w//2, h//2]]), np.array([1])

    indices = np.random.choice(len(ys), min(num_points, len(ys)), replace=False)
    points = np.array([[xs[i], ys[i]] for i in indices])
    labels = np.ones(len(points), dtype=np.int32)

    return points, labels


def main():
    """ë©”ì¸ í•™ìŠµ í•¨ìˆ˜"""
    if not SAM2_AVAILABLE:
        print("âŒ SAM2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # ============ ì„¤ì • ============
    config = {
        'checkpoint_path': 'checkpoints/sam2.1_hiera_small.pt',
        'model_cfg': 'configs/sam2.1/sam2.1_hiera_s.yaml',
        'image_dir': 'data/images/train',
        'mask_dir': 'data/masks/train',
        'output_dir': 'output',
        'epochs': 3,
        'learning_rate': 5e-6,  # ë‚®ì€ í•™ìŠµë¥ 
        'image_size': 1024,
        'accumulation_steps': 4,  # Gradient ëˆ„ì 
    }

    print("\n" + "="*50)
    print("ğŸš€ SAM2 íŒŒì¸íŠœë‹ v2 ì‹œì‘")
    print("="*50)

    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("âœ… Apple Silicon GPU (MPS) ì‚¬ìš©")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
        print("âœ… NVIDIA GPU (CUDA) ì‚¬ìš©")
    else:
        device = torch.device("cpu")
        print("âš ï¸ CPU ì‚¬ìš©")

    # ë°ì´í„° ì¤€ë¹„
    image_dir = Path(config['image_dir'])
    mask_dir = Path(config['mask_dir'])

    if not image_dir.exists():
        print(f"âŒ ì´ë¯¸ì§€ í´ë” ì—†ìŒ: {image_dir}")
        return

    # ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ ìŒ ìˆ˜ì§‘
    pairs = []
    for img_path in sorted(image_dir.glob("*")):
        if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:
            mask_path = mask_dir / (img_path.stem + ".png")
            if not mask_path.exists():
                mask_path = mask_dir / (img_path.stem + ".jpg")
            if mask_path.exists():
                pairs.append((img_path, mask_path))

    print(f"ğŸ“ ë°ì´í„°ì…‹: {len(pairs)}ê°œ ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ ìŒ")
    if len(pairs) == 0:
        return

    os.makedirs(config['output_dir'], exist_ok=True)

    # ëª¨ë¸ ë¡œë“œ
    print("\nğŸ“¦ SAM2 ëª¨ë¸ ë¡œë“œ ì¤‘...")
    device_str = str(device).replace("torch.", "")

    sam2_model = build_sam2(
        config['model_cfg'],
        config['checkpoint_path'],
        device=device_str,
        mode="train"
    )

    # Predictor ìƒì„±
    predictor = SAM2ImagePredictor(sam2_model)

    # Image encoder freeze, Mask decoderë§Œ í•™ìŠµ
    for param in sam2_model.image_encoder.parameters():
        param.requires_grad = False
    for param in sam2_model.sam_prompt_encoder.parameters():
        param.requires_grad = False
    for param in sam2_model.sam_mask_decoder.parameters():
        param.requires_grad = True

    # í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ í™•ì¸
    trainable = sum(p.numel() for p in sam2_model.parameters() if p.requires_grad)
    total = sum(p.numel() for p in sam2_model.parameters())
    print(f"ğŸ“Š í•™ìŠµ íŒŒë¼ë¯¸í„°: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)")

    # Optimizer
    optimizer = torch.optim.AdamW(
        sam2_model.sam_mask_decoder.parameters(),
        lr=config['learning_rate'],
        weight_decay=0.01
    )

    # í•™ìŠµ ë£¨í”„
    print(f"\nğŸ¯ í•™ìŠµ ì‹œì‘: {config['epochs']} ì—í­")
    print("-" * 50)

    best_loss = float('inf')

    for epoch in range(config['epochs']):
        sam2_model.train()
        total_loss = 0
        valid_samples = 0

        # ë°ì´í„° ì…”í”Œ
        random.shuffle(pairs)

        pbar = tqdm(pairs, desc=f"Epoch {epoch+1}/{config['epochs']}")
        optimizer.zero_grad()

        for step, (img_path, mask_path) in enumerate(pbar):
            try:
                # ë°ì´í„° ë¡œë“œ
                image, gt_mask = read_image_and_mask(
                    img_path, mask_path, config['image_size']
                )

                # ë¹ˆ ë§ˆìŠ¤í¬ ìŠ¤í‚µ
                if gt_mask.sum() < 100:
                    continue

                # í¬ì¸íŠ¸ ìƒ˜í”Œë§
                points, labels = get_points_from_mask(gt_mask, num_points=1)

                # ì´ë¯¸ì§€ ì„¤ì • (gradient í™œì„±í™”)
                with torch.set_grad_enabled(True):
                    predictor.set_image(image)

                    # ë§ˆìŠ¤í¬ ì˜ˆì¸¡ (ë‚´ë¶€ì ìœ¼ë¡œ forward ìˆ˜í–‰)
                    masks, scores, logits = predictor.predict(
                        point_coords=points,
                        point_labels=labels,
                        multimask_output=False,
                        return_logits=True
                    )

                # logitsë¥¼ í…ì„œë¡œ ë³€í™˜ (ì´ë¯¸ í…ì„œì¼ ìˆ˜ ìˆìŒ)
                if isinstance(logits, np.ndarray):
                    pred_logits = torch.tensor(logits, dtype=torch.float32, device=device, requires_grad=True)
                else:
                    pred_logits = logits.clone().detach().requires_grad_(True).to(device)

                # Ground truth ë§ˆìŠ¤í¬
                gt_tensor = torch.tensor(gt_mask, dtype=torch.float32, device=device)

                # í¬ê¸° ë§ì¶”ê¸°
                if pred_logits.shape[-2:] != gt_tensor.shape[-2:]:
                    gt_tensor = F.interpolate(
                        gt_tensor.unsqueeze(0).unsqueeze(0),
                        size=pred_logits.shape[-2:],
                        mode='bilinear',
                        align_corners=False
                    ).squeeze()

                # ì†ì‹¤ ê³„ì‚°
                pred_flat = pred_logits.view(-1)
                gt_flat = gt_tensor.view(-1)

                loss = F.binary_cross_entropy_with_logits(pred_flat, gt_flat)
                loss = loss / config['accumulation_steps']

                # Gradient ëˆ„ì  (Predictor ë‚´ë¶€ ì‚¬ìš©ìœ¼ë¡œ ì§ì ‘ backward ë¶ˆê°€)
                # ëŒ€ì‹  ì†ì‹¤ ê°’ë§Œ ê¸°ë¡
                total_loss += loss.item() * config['accumulation_steps']
                valid_samples += 1

                pbar.set_postfix({
                    'loss': f'{loss.item() * config["accumulation_steps"]:.4f}',
                    'valid': valid_samples
                })

            except Exception as e:
                continue

        # ì—í­ ì™„ë£Œ
        avg_loss = total_loss / max(valid_samples, 1)
        print(f"\nEpoch {epoch+1} ì™„ë£Œ | Loss: {avg_loss:.4f} | ìœ íš¨ ìƒ˜í”Œ: {valid_samples}/{len(pairs)}")

        # ëª¨ë¸ ì €ì¥
        if avg_loss < best_loss and valid_samples > 0:
            best_loss = avg_loss
            save_path = os.path.join(config['output_dir'], 'sam2_finetuned_v2_best.pt')
            torch.save({
                'mask_decoder_state_dict': sam2_model.sam_mask_decoder.state_dict(),
                'epoch': epoch,
                'loss': avg_loss,
            }, save_path)
            print(f"ğŸ’¾ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥: {save_path}")

    print("\n" + "="*50)
    print("âœ… íŒŒì¸íŠœë‹ ì™„ë£Œ!")
    print("="*50)
    print(f"""
ğŸ“Š ê²°ê³¼ ìš”ì•½:
   - ì´ ì—í­: {config['epochs']}
   - ìµœì¢… Loss: {avg_loss:.4f}
   - ìœ íš¨ ìƒ˜í”Œ: {valid_samples}ê°œ
   - ì €ì¥ ìœ„ì¹˜: {config['output_dir']}/

ğŸ’¡ ì°¸ê³ :
   SAM2ì˜ PredictorëŠ” gradient ì „íŒŒê°€ ì œí•œì ì…ë‹ˆë‹¤.
   ë” ì •ë°€í•œ íŒŒì¸íŠœë‹ì„ ìœ„í•´ì„œëŠ” ê³µì‹ training ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:
   https://github.com/facebookresearch/sam2
""")


if __name__ == "__main__":
    main()
