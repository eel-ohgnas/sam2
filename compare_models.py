"""
ì›ë³¸ SAM2 vs íŒŒì¸íŠœë‹ SAM2 ë¹„êµ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import numpy as np
import torch
import cv2
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm

from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor


def calculate_iou(pred_mask, gt_mask):
    """IoU ê³„ì‚°"""
    intersection = np.logical_and(pred_mask, gt_mask).sum()
    union = np.logical_or(pred_mask, gt_mask).sum()
    return intersection / (union + 1e-6)


def test_model(predictor, image_paths, mask_paths, desc="Testing"):
    """ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë° IoU ê³„ì‚°"""
    ious = []

    for img_path, mask_path in tqdm(zip(image_paths, mask_paths), total=len(image_paths), desc=desc):
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(str(img_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # GT ë§ˆìŠ¤í¬ ë¡œë“œ
        gt_mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)
        gt_mask = (gt_mask > 127).astype(np.uint8)

        # ë§ˆìŠ¤í¬ì—ì„œ í¬ì¸íŠ¸ ìƒ˜í”Œë§
        coords = np.argwhere(gt_mask > 0)
        if len(coords) == 0:
            continue
        yx = coords[len(coords) // 2]  # ì¤‘ì•™ í¬ì¸íŠ¸
        point = np.array([[yx[1], yx[0]]])
        label = np.array([1])

        # ì˜ˆì¸¡
        predictor.set_image(image)
        masks, scores, _ = predictor.predict(
            point_coords=point,
            point_labels=label,
            multimask_output=True
        )

        # ê°€ì¥ ì¢‹ì€ ë§ˆìŠ¤í¬ ì„ íƒ
        best_idx = np.argmax(scores)
        pred_mask = masks[best_idx]

        # GT ë§ˆìŠ¤í¬ ë¦¬ì‚¬ì´ì¦ˆ
        if gt_mask.shape != pred_mask.shape:
            gt_mask = cv2.resize(gt_mask, (pred_mask.shape[1], pred_mask.shape[0]),
                                interpolation=cv2.INTER_NEAREST)

        # IoU ê³„ì‚°
        iou = calculate_iou(pred_mask, gt_mask > 0)
        ious.append(iou)

    return np.mean(ious), ious


def visualize_comparison(image_path, mask_path, predictor_original, predictor_finetuned, output_path):
    """ë¹„êµ ì‹œê°í™”"""
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = cv2.imread(str(image_path))
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # GT ë§ˆìŠ¤í¬ ë¡œë“œ
    gt_mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)
    gt_mask = (gt_mask > 127)

    # í¬ì¸íŠ¸ ì„ íƒ
    coords = np.argwhere(gt_mask > 0)
    if len(coords) == 0:
        return
    yx = coords[len(coords) // 2]
    point = np.array([[yx[1], yx[0]]])
    label = np.array([1])

    # ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡
    predictor_original.set_image(image)
    masks_orig, scores_orig, _ = predictor_original.predict(
        point_coords=point, point_labels=label, multimask_output=True
    )
    best_orig = masks_orig[np.argmax(scores_orig)]

    # íŒŒì¸íŠœë‹ ëª¨ë¸ ì˜ˆì¸¡
    predictor_finetuned.set_image(image)
    masks_ft, scores_ft, _ = predictor_finetuned.predict(
        point_coords=point, point_labels=label, multimask_output=True
    )
    best_ft = masks_ft[np.argmax(scores_ft)]

    # ì‹œê°í™”
    fig, axes = plt.subplots(1, 4, figsize=(20, 5))

    # ì›ë³¸ ì´ë¯¸ì§€ + í¬ì¸íŠ¸
    axes[0].imshow(image)
    axes[0].scatter(point[0, 0], point[0, 1], c='lime', s=200, marker='*')
    axes[0].set_title("Input Image")
    axes[0].axis("off")

    # Ground Truth
    axes[1].imshow(image)
    axes[1].imshow(gt_mask, alpha=0.5, cmap='Reds')
    axes[1].set_title("Ground Truth")
    axes[1].axis("off")

    # ì›ë³¸ SAM2
    iou_orig = calculate_iou(best_orig, gt_mask)
    axes[2].imshow(image)
    axes[2].imshow(best_orig, alpha=0.5, cmap='Blues')
    axes[2].set_title(f"Original SAM2\nIoU: {iou_orig:.2%}")
    axes[2].axis("off")

    # íŒŒì¸íŠœë‹ SAM2
    iou_ft = calculate_iou(best_ft, gt_mask)
    axes[3].imshow(image)
    axes[3].imshow(best_ft, alpha=0.5, cmap='Greens')
    axes[3].set_title(f"Fine-tuned SAM2\nIoU: {iou_ft:.2%}")
    axes[3].axis("off")

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()


def main():
    print("\n" + "="*60)
    print("ğŸ”¬ ì›ë³¸ vs íŒŒì¸íŠœë‹ SAM2 ë¹„êµ")
    print("="*60)

    # ì„¤ì •
    config = {
        'model_cfg': 'configs/sam2.1/sam2.1_hiera_s.yaml',
        'original_checkpoint': 'checkpoints/sam2.1_hiera_small.pt',
        'finetuned_checkpoint': 'output/sam2_best.pt',
        'test_image_dir': 'data/images/val',
        'test_mask_dir': 'data/masks/val',
        'output_dir': 'output/comparison',
    }

    os.makedirs(config['output_dir'], exist_ok=True)

    # ë””ë°”ì´ìŠ¤
    if torch.backends.mps.is_available():
        device = "mps"
    elif torch.cuda.is_available():
        device = "cuda"
    else:
        device = "cpu"
    print(f"ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {device}")

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    test_image_dir = Path(config['test_image_dir'])
    test_mask_dir = Path(config['test_mask_dir'])

    image_paths = []
    mask_paths = []
    for img_path in sorted(test_image_dir.glob("*")):
        if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:
            mask_path = test_mask_dir / (img_path.stem + ".png")
            if mask_path.exists():
                image_paths.append(img_path)
                mask_paths.append(mask_path)

    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(image_paths)}ê°œ")

    # ì›ë³¸ ëª¨ë¸ ë¡œë“œ
    print("\nğŸ“¦ ì›ë³¸ SAM2 ë¡œë“œ ì¤‘...")
    model_original = build_sam2(
        config['model_cfg'],
        config['original_checkpoint'],
        device=device
    )
    predictor_original = SAM2ImagePredictor(model_original)

    # íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ
    print("ğŸ“¦ íŒŒì¸íŠœë‹ SAM2 ë¡œë“œ ì¤‘...")
    model_finetuned = build_sam2(
        config['model_cfg'],
        config['original_checkpoint'],  # ë¨¼ì € ì›ë³¸ êµ¬ì¡° ë¡œë“œ
        device=device
    )
    # íŒŒì¸íŠœë‹ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    state_dict = torch.load(config['finetuned_checkpoint'], map_location=device)
    model_finetuned.load_state_dict(state_dict)
    predictor_finetuned = SAM2ImagePredictor(model_finetuned)

    # í…ŒìŠ¤íŠ¸ (ì²˜ìŒ 50ê°œë§Œ)
    test_size = min(50, len(image_paths))
    print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì¤‘... ({test_size}ê°œ ì´ë¯¸ì§€)")

    iou_original, ious_orig = test_model(
        predictor_original,
        image_paths[:test_size],
        mask_paths[:test_size],
        "ì›ë³¸ SAM2"
    )

    iou_finetuned, ious_ft = test_model(
        predictor_finetuned,
        image_paths[:test_size],
        mask_paths[:test_size],
        "íŒŒì¸íŠœë‹ SAM2"
    )

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š ê²°ê³¼ ë¹„êµ")
    print("="*60)
    print(f"""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚           í‰ê·  IoU ë¹„êµ                  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  ì›ë³¸ SAM2:      {iou_original:.2%}               â”‚
    â”‚  íŒŒì¸íŠœë‹ SAM2:  {iou_finetuned:.2%}               â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  ğŸš€ ê°œì„ ìœ¨:      +{(iou_finetuned - iou_original)*100:.1f}%p              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    # ë¹„êµ ì‹œê°í™” (ì²˜ìŒ 5ê°œ)
    print("ğŸ–¼ï¸ ë¹„êµ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
    for i in range(min(5, len(image_paths))):
        output_path = os.path.join(config['output_dir'], f"compare_{i+1}.png")
        visualize_comparison(
            image_paths[i],
            mask_paths[i],
            predictor_original,
            predictor_finetuned,
            output_path
        )
        print(f"  ğŸ’¾ {output_path}")

    print(f"\nâœ… ì™„ë£Œ! ë¹„êµ ì´ë¯¸ì§€: {config['output_dir']}/")


if __name__ == "__main__":
    main()
