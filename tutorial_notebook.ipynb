{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ SAM2 íŒŒì¸íŠœë‹ íŠœí† ë¦¬ì–¼\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ SAM2(Segment Anything Model 2)ë¥¼ íŒŒì¸íŠœë‹í•˜ëŠ” ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ëª©í‘œ**: ì ì€ ë°ì´í„°ì™€ ë¦¬ì†ŒìŠ¤ë¡œ íŠ¹ì • ë„ë©”ì¸ì— ë§ëŠ” ì„¸ë¶„í™” ëª¨ë¸ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ í™•ì¸\n",
    "\n",
    "ë¨¼ì € í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™˜ê²½ í™•ì¸\n",
    "import sys\n",
    "print(f\"Python ë²„ì „: {sys.version}\")\n",
    "\n",
    "# PyTorch í™•ì¸\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
    "    print(f\"MPS (Apple Silicon) ì‚¬ìš© ê°€ëŠ¥: {torch.backends.mps.is_available()}\")\n",
    "    print(f\"CUDA (NVIDIA) ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "except ImportError:\n",
    "    print(\"âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ì„¤ì¹˜: pip install torch torchvision\")\n",
    "\n",
    "# SAM2 í™•ì¸\n",
    "try:\n",
    "    from sam2.build_sam import build_sam2\n",
    "    print(\"âœ… SAM2 ì„¤ì¹˜ í™•ì¸ë¨\")\n",
    "except ImportError:\n",
    "    print(\"âŒ SAM2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ì„¤ì¹˜: pip install git+https://github.com/facebookresearch/sam2.git\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° í´ë” êµ¬ì¡° ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° í´ë” ìƒì„±\n",
    "from pathlib import Path\n",
    "\n",
    "folders = [\n",
    "    \"data/images/train\",\n",
    "    \"data/images/val\",\n",
    "    \"data/masks/train\",\n",
    "    \"data/masks/val\",\n",
    "    \"checkpoints\",\n",
    "    \"output\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âœ… {folder}\")\n",
    "\n",
    "print(\"\\nğŸ“ í´ë” êµ¬ì¡° ìƒì„± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SAM2 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "ì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ë©´ SAM2 ì²´í¬í¬ì¸íŠ¸ê°€ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "checkpoint_url = \"https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_small.pt\"\n",
    "checkpoint_path = \"checkpoints/sam2.1_hiera_small.pt\"\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(\"ğŸ“¥ SAM2 ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì•½ 185MB)\")\n",
    "    urllib.request.urlretrieve(checkpoint_url, checkpoint_path)\n",
    "    print(f\"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {checkpoint_path}\")\n",
    "else:\n",
    "    print(f\"âœ… ì²´í¬í¬ì¸íŠ¸ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SAM2 ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"ğŸ Apple Silicon GPU ì‚¬ìš©\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"ğŸ® NVIDIA GPU ì‚¬ìš©\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"ğŸ’» CPU ì‚¬ìš©\")\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "print(\"\\nğŸ“¦ SAM2 ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "model = build_sam2(\"sam2.1_hiera_s\", \"checkpoints/sam2.1_hiera_small.pt\")\n",
    "model = model.to(device)\n",
    "predictor = SAM2ImagePredictor(model)\n",
    "print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì‹¤ì œ íŒŒì¸íŠœë‹ ì „ì— ì›ë³¸ SAM2ê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=200):\n",
    "    pos_points = coords[labels == 1]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green',\n",
    "               marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "# ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± (í…ŒìŠ¤íŠ¸ìš© - ì‹¤ì œë¡œëŠ” ìì‹ ì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”)\n",
    "print(\"ğŸ–¼ï¸ ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "sample_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "# ì¤‘ì•™ì— ì› ê·¸ë¦¬ê¸° (ì„¸ë¶„í™” ëŒ€ìƒ)\n",
    "from PIL import ImageDraw\n",
    "img_pil = Image.fromarray(sample_image)\n",
    "draw = ImageDraw.Draw(img_pil)\n",
    "draw.ellipse([220, 140, 420, 340], fill=(255, 100, 100))\n",
    "sample_image = np.array(img_pil)\n",
    "\n",
    "# ì„¸ë¶„í™” í…ŒìŠ¤íŠ¸\n",
    "predictor.set_image(sample_image)\n",
    "\n",
    "# ì¤‘ì•™ í¬ì¸íŠ¸ í´ë¦­\n",
    "input_point = np.array([[320, 240]])  # ì¤‘ì•™\n",
    "input_label = np.array([1])  # foreground\n",
    "\n",
    "masks, scores, logits = predictor.predict(\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    multimask_output=True\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "axes[0].imshow(sample_image)\n",
    "show_points(input_point, input_label, axes[0])\n",
    "axes[0].set_title(\"Input Image + Point\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "    axes[i+1].imshow(sample_image)\n",
    "    show_mask(mask, axes[i+1])\n",
    "    axes[i+1].set_title(f\"Mask {i+1} (score: {score:.3f})\")\n",
    "    axes[i+1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… SAM2 í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(\"ğŸ’¡ ì´ì œ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ data/images/train í´ë”ì— ë„£ê³  íŒŒì¸íŠœë‹ì„ ì‹œì‘í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "1. **ë°ì´í„° ì¤€ë¹„**: `data/images/train`ì— ì´ë¯¸ì§€, `data/masks/train`ì— ë§ˆìŠ¤í¬ ë„£ê¸°\n",
    "2. **íŒŒì¸íŠœë‹ ì‹¤í–‰**: `python finetune_sam2.py`\n",
    "3. **í…ŒìŠ¤íŠ¸**: `python test_sam2.py`\n",
    "\n",
    "ìì„¸í•œ ë‚´ìš©ì€ `setup_guide.md`ë¥¼ ì°¸ê³ í•˜ì„¸ìš”."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
