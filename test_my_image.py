"""
ë‚´ ì´ë¯¸ì§€ë¡œ SAM2 í…ŒìŠ¤íŠ¸í•˜ê¸°
ì‚¬ìš©ë²•: python test_my_image.py --image ì´ë¯¸ì§€ê²½ë¡œ.jpg
"""

import argparse
import numpy as np
import torch
import cv2
import matplotlib.pyplot as plt
from pathlib import Path

from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor


def load_model(use_finetuned=True):
    """ëª¨ë¸ ë¡œë“œ"""
    config = 'configs/sam2.1/sam2.1_hiera_s.yaml'

    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if torch.backends.mps.is_available():
        device = "mps"
    elif torch.cuda.is_available():
        device = "cuda"
    else:
        device = "cpu"

    print(f"ë””ë°”ì´ìŠ¤: {device}")

    # ëª¨ë¸ ë¡œë“œ
    original_checkpoint = 'checkpoints/sam2.1_hiera_small.pt'
    model = build_sam2(config, original_checkpoint, device=device)

    if use_finetuned:
        finetuned_checkpoint = 'output/sam2_best.pt'
        if Path(finetuned_checkpoint).exists():
            state_dict = torch.load(finetuned_checkpoint, map_location=device)
            model.load_state_dict(state_dict)
            print("âœ… íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        else:
            print("âš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸ ì—†ìŒ, ì›ë³¸ ëª¨ë¸ ì‚¬ìš©")
    else:
        print("ğŸ“¦ ì›ë³¸ SAM2 ëª¨ë¸ ì‚¬ìš©")

    return SAM2ImagePredictor(model)


def interactive_segment(image_path, predictor, output_dir="output/my_results"):
    """ì¸í„°ë™í‹°ë¸Œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = cv2.imread(str(image_path))
    if image is None:
        print(f"âŒ ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return

    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    print(f"ğŸ“· ì´ë¯¸ì§€ í¬ê¸°: {image.shape[1]} x {image.shape[0]}")

    # ì¶œë ¥ í´ë” ìƒì„±
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # í´ë¦­ í¬ì¸íŠ¸ ì €ì¥
    points = []
    labels = []

    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    ax.imshow(image)
    ax.set_title("í´ë¦­ìœ¼ë¡œ í¬ì¸íŠ¸ ì¶”ê°€ (ì¢Œí´ë¦­=ì „ê²½, ìš°í´ë¦­=ë°°ê²½)\në‹«ìœ¼ë©´ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰")
    ax.axis('off')

    def onclick(event):
        if event.xdata is None or event.ydata is None:
            return

        x, y = int(event.xdata), int(event.ydata)

        if event.button == 1:  # ì¢Œí´ë¦­ = ì „ê²½
            points.append([x, y])
            labels.append(1)
            ax.scatter(x, y, c='lime', s=200, marker='*', edgecolors='white', linewidths=2)
            print(f"  âœ… ì „ê²½ í¬ì¸íŠ¸ ì¶”ê°€: ({x}, {y})")
        elif event.button == 3:  # ìš°í´ë¦­ = ë°°ê²½
            points.append([x, y])
            labels.append(0)
            ax.scatter(x, y, c='red', s=200, marker='x', linewidths=3)
            print(f"  âŒ ë°°ê²½ í¬ì¸íŠ¸ ì¶”ê°€: ({x}, {y})")

        fig.canvas.draw()

    fig.canvas.mpl_connect('button_press_event', onclick)
    print("\nğŸ–±ï¸ ì´ë¯¸ì§€ë¥¼ í´ë¦­í•˜ì„¸ìš”:")
    print("   - ì¢Œí´ë¦­: ì „ê²½ (ì„¸ê·¸ë©˜íŠ¸í•  ì˜ì—­)")
    print("   - ìš°í´ë¦­: ë°°ê²½ (ì œì™¸í•  ì˜ì—­)")
    print("   - ì°½ ë‹«ê¸°: ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰\n")

    plt.show()

    if len(points) == 0:
        print("âš ï¸ í¬ì¸íŠ¸ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰
    print(f"\nğŸ”„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰ ì¤‘... ({len(points)}ê°œ í¬ì¸íŠ¸)")

    predictor.set_image(image)

    masks, scores, _ = predictor.predict(
        point_coords=np.array(points),
        point_labels=np.array(labels),
        multimask_output=True
    )

    # ê²°ê³¼ ì‹œê°í™”
    fig, axes = plt.subplots(2, 2, figsize=(14, 12))

    # ì›ë³¸ ì´ë¯¸ì§€ + í¬ì¸íŠ¸
    axes[0, 0].imshow(image)
    for i, (pt, lb) in enumerate(zip(points, labels)):
        color = 'lime' if lb == 1 else 'red'
        marker = '*' if lb == 1 else 'x'
        axes[0, 0].scatter(pt[0], pt[1], c=color, s=200, marker=marker, edgecolors='white', linewidths=2)
    axes[0, 0].set_title("ì…ë ¥ ì´ë¯¸ì§€ + í¬ì¸íŠ¸")
    axes[0, 0].axis('off')

    # 3ê°œ ë§ˆìŠ¤í¬ ì¶œë ¥
    colors = ['Blues', 'Greens', 'Oranges']
    for i, (mask, score) in enumerate(zip(masks, scores)):
        row, col = (0, 1) if i == 0 else (1, i-1)
        axes[row, col].imshow(image)
        axes[row, col].imshow(mask, alpha=0.6, cmap=colors[i])
        axes[row, col].set_title(f"ë§ˆìŠ¤í¬ {i+1} (Score: {score:.2%})")
        axes[row, col].axis('off')

    plt.tight_layout()

    # ì €ì¥
    img_name = Path(image_path).stem
    output_path = f"{output_dir}/{img_name}_result.png"
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")

    plt.show()

    # ë² ìŠ¤íŠ¸ ë§ˆìŠ¤í¬ ì €ì¥
    best_idx = np.argmax(scores)
    mask_output = (masks[best_idx] * 255).astype(np.uint8)
    mask_path = f"{output_dir}/{img_name}_mask.png"
    cv2.imwrite(mask_path, mask_output)
    print(f"ğŸ’¾ ë§ˆìŠ¤í¬ ì €ì¥: {mask_path}")

    return masks[best_idx]


def batch_segment(image_path, predictor, points_list, output_dir="output/my_results"):
    """ì¢Œí‘œë¥¼ ì§ì ‘ ì§€ì •í•´ì„œ ì„¸ê·¸ë©˜í…Œì´ì…˜ (GUI ì—†ì´)"""
    image = cv2.imread(str(image_path))
    if image is None:
        print(f"âŒ ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return

    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    predictor.set_image(image)

    points = np.array([[p[0], p[1]] for p in points_list])
    labels = np.array([p[2] if len(p) > 2 else 1 for p in points_list])

    masks, scores, _ = predictor.predict(
        point_coords=points,
        point_labels=labels,
        multimask_output=True
    )

    best_idx = np.argmax(scores)
    best_mask = masks[best_idx]

    # ê²°ê³¼ ì €ì¥
    img_name = Path(image_path).stem

    # ì‹œê°í™”
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    axes[0].imshow(image)
    for pt, lb in zip(points, labels):
        color = 'lime' if lb == 1 else 'red'
        axes[0].scatter(pt[0], pt[1], c=color, s=200, marker='*')
    axes[0].set_title("ì…ë ¥")
    axes[0].axis('off')

    axes[1].imshow(best_mask, cmap='gray')
    axes[1].set_title(f"ë§ˆìŠ¤í¬ (Score: {scores[best_idx]:.2%})")
    axes[1].axis('off')

    axes[2].imshow(image)
    axes[2].imshow(best_mask, alpha=0.5, cmap='Greens')
    axes[2].set_title("ì˜¤ë²„ë ˆì´")
    axes[2].axis('off')

    plt.tight_layout()
    output_path = f"{output_dir}/{img_name}_result.png"
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()

    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
    return best_mask


def main():
    parser = argparse.ArgumentParser(description="ë‚´ ì´ë¯¸ì§€ë¡œ SAM2 í…ŒìŠ¤íŠ¸")
    parser.add_argument("--image", "-i", type=str, required=True, help="í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ")
    parser.add_argument("--original", action="store_true", help="ì›ë³¸ SAM2 ì‚¬ìš© (ê¸°ë³¸: íŒŒì¸íŠœë‹ ëª¨ë¸)")
    parser.add_argument("--point", "-p", type=str, help="í¬ì¸íŠ¸ ì¢Œí‘œ (ì˜ˆ: '100,200' ë˜ëŠ” '100,200,1;300,400,0')")
    parser.add_argument("--output", "-o", type=str, default="output/my_results", help="ì¶œë ¥ í´ë”")

    args = parser.parse_args()

    print("\n" + "="*50)
    print("ğŸ¯ SAM2 ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸")
    print("="*50)

    # ëª¨ë¸ ë¡œë“œ
    predictor = load_model(use_finetuned=not args.original)

    if args.point:
        # ì¢Œí‘œ ì§ì ‘ ì§€ì •
        points = []
        for pt_str in args.point.split(';'):
            parts = pt_str.split(',')
            x, y = int(parts[0]), int(parts[1])
            label = int(parts[2]) if len(parts) > 2 else 1
            points.append([x, y, label])

        batch_segment(args.image, predictor, points, args.output)
    else:
        # ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ
        interactive_segment(args.image, predictor, args.output)

    print("\nâœ… ì™„ë£Œ!")


if __name__ == "__main__":
    main()
