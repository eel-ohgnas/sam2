"""
SAM2 íŒŒì¸íŠœë‹ ìŠ¤í¬ë¦½íŠ¸ (ì´ˆë³´ììš©)
ì°¸ê³ : https://github.com/sagieppel/fine-tune-train_segment_anything_2_in_60_lines_of_code

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” SAM2ì˜ Mask Decoderë§Œ íŒŒì¸íŠœë‹í•©ë‹ˆë‹¤.
- ì¥ì : ì ì€ GPU ë©”ëª¨ë¦¬, ë¹ ë¥¸ í•™ìŠµ
- í•„ìš” GPU ë©”ëª¨ë¦¬: ~8GB
"""

import os
import random
from pathlib import Path

import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
from tqdm import tqdm

# SAM2 imports
try:
    from sam2.build_sam import build_sam2
    SAM2_AVAILABLE = True
except ImportError:
    SAM2_AVAILABLE = False
    print("âš ï¸ SAM2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. setup_guide.mdë¥¼ ì°¸ê³ í•˜ì„¸ìš”.")


def load_image_and_mask(image_path, mask_path, image_size=1024):
    """ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = Image.open(image_path).convert("RGB")
    image = image.resize((image_size, image_size))
    image = np.array(image)

    # ë§ˆìŠ¤í¬ ë¡œë“œ
    mask = Image.open(mask_path).convert("L")
    mask = mask.resize((image_size, image_size), Image.NEAREST)
    mask = np.array(mask) > 127  # ì´ì§„í™”

    return image, mask


def get_random_point_in_mask(mask):
    """ë§ˆìŠ¤í¬ ë‚´ë¶€ì—ì„œ ëœë¤ í¬ì¸íŠ¸ë¥¼ ì„ íƒí•©ë‹ˆë‹¤."""
    coords = np.where(mask)
    if len(coords[0]) == 0:
        # ë§ˆìŠ¤í¬ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì¤‘ì•™ì  ë°˜í™˜
        return np.array([[mask.shape[1] // 2, mask.shape[0] // 2]])

    idx = np.random.randint(len(coords[0]))
    return np.array([[coords[1][idx], coords[0][idx]]])  # (x, y)


def train_one_epoch(model, image_paths, mask_paths, optimizer, device, image_size=1024):
    """í•œ ì—í­ í•™ìŠµ - ëª¨ë¸ ì§ì ‘ ì‚¬ìš©"""
    model.train()

    # Image encoderëŠ” freeze, mask decoderë§Œ í•™ìŠµ
    for param in model.image_encoder.parameters():
        param.requires_grad = False
    for param in model.sam_mask_decoder.parameters():
        param.requires_grad = True

    total_loss = 0
    indices = list(range(len(image_paths)))
    random.shuffle(indices)

    pbar = tqdm(indices, desc="Training")
    for idx in pbar:
        try:
            # ë°ì´í„° ë¡œë“œ
            image, gt_mask = load_image_and_mask(
                image_paths[idx], mask_paths[idx], image_size
            )

            if not gt_mask.any():  # ë¹ˆ ë§ˆìŠ¤í¬ ìŠ¤í‚µ
                continue

            # ëœë¤ í¬ì¸íŠ¸ ì„ íƒ
            point_coords = get_random_point_in_mask(gt_mask)

            # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜ (B, C, H, W)
            image_tensor = torch.tensor(image, dtype=torch.float32, device=device)
            image_tensor = image_tensor.permute(2, 0, 1).unsqueeze(0)  # (1, 3, H, W)
            image_tensor = image_tensor / 255.0  # ì •ê·œí™”

            # íƒ€ê²Ÿ ë§ˆìŠ¤í¬
            gt_mask_tensor = torch.tensor(gt_mask, dtype=torch.float32, device=device)
            gt_mask_256 = F.interpolate(
                gt_mask_tensor.unsqueeze(0).unsqueeze(0),
                size=(256, 256),
                mode='bilinear',
                align_corners=False
            ).squeeze()

            # í¬ì¸íŠ¸ ì¢Œí‘œ í…ì„œ
            point_coords_tensor = torch.tensor(point_coords, dtype=torch.float32, device=device)
            point_coords_tensor = point_coords_tensor.unsqueeze(0)  # (1, N, 2)
            point_labels = torch.ones((1, point_coords_tensor.shape[1]), dtype=torch.int32, device=device)

            # Forward pass with gradient
            with torch.amp.autocast(device_type=device.type if device.type != 'mps' else 'cpu', enabled=False):
                # Image encoding (no grad)
                with torch.no_grad():
                    backbone_out = model.forward_image(image_tensor)
                    _, vision_feats, _, _ = model._prepare_backbone_features(backbone_out)

                    # ìˆ˜ì •: ë§ˆì§€ë§‰ feature ì‚¬ìš©
                    if len(vision_feats) > 0:
                        feat = vision_feats[-1]
                        if feat.dim() == 3:  # (B, N, C) -> (B, C, H, W)
                            B, N, C = feat.shape
                            H = W = int(N ** 0.5)
                            feat = feat.permute(0, 2, 1).reshape(B, C, H, W)
                        image_embed = feat
                    else:
                        continue

                # Point ì„ë² ë”© ìƒì„±
                concat_points = (point_coords_tensor, point_labels)
                sparse_embeddings, dense_embeddings = model.sam_prompt_encoder(
                    points=concat_points,
                    boxes=None,
                    masks=None,
                )

                # Mask decoder (with grad)
                low_res_masks, iou_predictions, _, _ = model.sam_mask_decoder(
                    image_embeddings=image_embed,
                    image_pe=model.sam_prompt_encoder.get_dense_pe(),
                    sparse_prompt_embeddings=sparse_embeddings,
                    dense_prompt_embeddings=dense_embeddings,
                    multimask_output=True,
                    repeat_image=False,
                )

                # ì†ì‹¤ ê³„ì‚°
                pred_mask = low_res_masks[:, 0, :, :]  # ì²« ë²ˆì§¸ ë§ˆìŠ¤í¬ ì‚¬ìš©
                pred_mask = F.interpolate(
                    pred_mask.unsqueeze(1),
                    size=(256, 256),
                    mode='bilinear',
                    align_corners=False
                ).squeeze()

                loss = F.binary_cross_entropy_with_logits(pred_mask, gt_mask_256)

            # ì—­ì „íŒŒ
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            pbar.set_postfix({'loss': f'{loss.item():.4f}'})

        except Exception as e:
            print(f"\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ (ìŠ¤í‚µ): {e}")
            continue

    return total_loss / max(len(indices), 1)


def main():
    """ë©”ì¸ í•™ìŠµ í•¨ìˆ˜"""

    if not SAM2_AVAILABLE:
        print("âŒ SAM2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ“– setup_guide.mdë¥¼ ì°¸ê³ í•˜ì—¬ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        return

    # ============ ì„¤ì • ============
    config = {
        'checkpoint_path': 'checkpoints/sam2.1_hiera_small.pt',
        'model_cfg': 'configs/sam2.1/sam2.1_hiera_s.yaml',
        'image_dir': 'data/images/train',
        'mask_dir': 'data/masks/train',
        'output_dir': 'output',
        'epochs': 5,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì¤„ì„
        'learning_rate': 1e-5,
        'image_size': 1024,
    }

    print("\n" + "="*50)
    print("ğŸš€ SAM2 íŒŒì¸íŠœë‹ ì‹œì‘")
    print("="*50)

    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("âœ… Apple Silicon GPU (MPS) ì‚¬ìš©")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
        print("âœ… NVIDIA GPU (CUDA) ì‚¬ìš©")
    else:
        device = torch.device("cpu")
        print("âš ï¸ CPU ì‚¬ìš© (ëŠë¦´ ìˆ˜ ìˆìŒ)")

    # ì²´í¬í¬ì¸íŠ¸ í™•ì¸
    if not os.path.exists(config['checkpoint_path']):
        print(f"\nâŒ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config['checkpoint_path']}")
        return

    # ë°ì´í„° ê²½ë¡œ ìˆ˜ì§‘
    image_dir = Path(config['image_dir'])
    mask_dir = Path(config['mask_dir'])

    if not image_dir.exists():
        print(f"\nâŒ ì´ë¯¸ì§€ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        print("ğŸ“‚ python download_dataset.py ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    # ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ ìŒ ì°¾ê¸°
    image_paths = []
    mask_paths = []

    for img_path in sorted(image_dir.glob("*")):
        if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:
            mask_path = mask_dir / (img_path.stem + ".png")
            if not mask_path.exists():
                mask_path = mask_dir / (img_path.stem + ".jpg")
            if mask_path.exists():
                image_paths.append(img_path)
                mask_paths.append(mask_path)

    print(f"ğŸ“ ë°ì´í„°ì…‹: {len(image_paths)}ê°œ ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ ìŒ")

    if len(image_paths) == 0:
        print("âŒ ìœ íš¨í•œ ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ ìŒì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(config['output_dir'], exist_ok=True)

    # ëª¨ë¸ ë¡œë“œ
    print("\nğŸ“¦ SAM2 ëª¨ë¸ ë¡œë“œ ì¤‘...")
    device_str = "mps" if device.type == "mps" else ("cuda" if device.type == "cuda" else "cpu")

    model = build_sam2(
        config['model_cfg'],
        config['checkpoint_path'],
        device=device_str,
        mode="train"  # í•™ìŠµ ëª¨ë“œ
    )

    # ì˜µí‹°ë§ˆì´ì € ì„¤ì • (Mask Decoderë§Œ í•™ìŠµ)
    optimizer = torch.optim.AdamW(
        model.sam_mask_decoder.parameters(),
        lr=config['learning_rate']
    )

    # í•™ìŠµ ë£¨í”„
    print(f"\nğŸ¯ í•™ìŠµ ì‹œì‘: {config['epochs']} ì—í­")
    print("-" * 50)

    best_loss = float('inf')
    for epoch in range(config['epochs']):
        loss = train_one_epoch(
            model, image_paths, mask_paths,
            optimizer, device, config['image_size']
        )
        print(f"\nEpoch {epoch+1}/{config['epochs']} | Average Loss: {loss:.4f}")

        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥
        if loss < best_loss:
            best_loss = loss
            save_path = os.path.join(config['output_dir'], 'sam2_finetuned_best.pt')
            torch.save({
                'model_state_dict': model.sam_mask_decoder.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'epoch': epoch,
                'loss': loss,
            }, save_path)
            print(f"ğŸ’¾ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥: {save_path}")

    # ìµœì¢… ëª¨ë¸ ì €ì¥
    final_path = os.path.join(config['output_dir'], 'sam2_finetuned_final.pt')
    torch.save({
        'model_state_dict': model.sam_mask_decoder.state_dict(),
        'epoch': config['epochs'],
        'loss': loss,
    }, final_path)
    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ! ìµœì¢… ëª¨ë¸: {final_path}")


if __name__ == "__main__":
    main()
